{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precinct Matching Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_id = 'Ulster County'\n",
    "\n",
    "county_results_filename = 'election_results_county_id={}.csv'.format(county_id)\n",
    "county_results_df = pd.read_csv(county_results_filename)\n",
    "county_shapefile_filename = 'shapefile_county_id={}'.format(county_id)\n",
    "county_shapefile_gdf = gpd.read_file(county_shapefile_filename)\n",
    "\n",
    "# correct for the truncation caused by 10 character column name limit in shapefiles\n",
    "county_shapefile_gdf.rename(columns={'original_p':'original_precinct_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell aliases `county_results_df` as `df` and `county_shapefile_gdf` as `gdf` here because typing fewer characters allows for faster data exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = county_results_df.copy()\n",
    "gdf = county_shapefile_gdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Preconditions\n",
    "These should all pass - they're here to ensure that everything in `config.ipynb` worked correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Pass the precondition described above which takes the form of an assert statement in this cell.\n",
    "assert 'county_id' in df.columns and 'county_id' in gdf.columns\n",
    "assert 'original_precinct_name' in df.columns and 'original_precinct_name' in gdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Modifications\n",
    "Its normally benificial to apply some modifications uniformly to all precincts. For example, its good practice to make everything lower case. This modification is made in `edit_precinct_name` - read its specification to learn more about how to use it to make more modifications. Consider removing substrings that appear in every precinct name like `voting district`. Be careful of removing words that will result in duplicate precinct names. For example, if there are two `Newtown Voting District` precincts in the shapefile, and the election results have `Newtown Boro` and `Newtown Township`, its okay to remove `Voting District`, but you probably don't want to remove `Boro` or `Township`. Of course, this will differ from County to County - so be vigilant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def edit_precinct_name(prec_name, \n",
    "    remove_lst=[], \n",
    "    target_to_replacement={},\n",
    "    stopping_words=[],\n",
    "    prec_dict={}):\n",
    "    '''\n",
    "    Returns a lower case precinct name (string) with certian modifications depending other arguments. \n",
    "    \n",
    "    Modifications are performed in order of the parameters they depend on. By convention, case is \n",
    "    ignored by making prec_name lower case. Accordingly, one should pass arguements with lower case\n",
    "    elements. That is, keys of the dictionaries and elements of lists should be lower case strings.\n",
    "\n",
    "\tParameters:\n",
    "\t\tprec_name (str): precinct name\n",
    "\t\tremove_lst ((str) list): if a string in this list is a substring in prec_name it will be removed. \n",
    "            All elements should be lower case.\n",
    "        target_to_replacement ({str:str} dictionary): keys (targets) will be replaced with their \n",
    "            corresponding value (replacements) in prec_name. All keys should be lower case.\n",
    "        stopping_words ({str} list): If any substring of prec_name contains a element of stopping_words\n",
    "             that is adjacent to a space character it will be removed. All elements should be lower case.\n",
    "        prec_dict ({str:str} dictionary): After all the modifications above, if the edited prec_name\n",
    "            string is in the set of keys for prec_dict, then it will be replaced with that key's value.  \n",
    "            All keys should be lower case.\n",
    "\n",
    "\tReturns:\n",
    "\t\tprec_name (str): prec_name arguement returned with the \n",
    "    '''\n",
    "    prec_name = str(prec_name).lower()\n",
    "    for word in remove_lst:\n",
    "        prec_name = prec_name.replace(word, '')\n",
    "    for target, replacement in target_to_replacement.items():\n",
    "        prec_name = prec_name.replace(target, replacement)\n",
    "    words = prec_name.split()\n",
    "    words = [word.lstrip('0') for word in words if word not in stopping_words]\n",
    "    prec_name = \" \".join(words)\n",
    "    return prec_dict[prec_name] if prec_name in prec_dict.keys() else prec_name\n",
    "\n",
    "df_to_gdf = {\n",
    "}\n",
    "\n",
    "gdf_to_df = {\n",
    "}\n",
    "\n",
    "# Tune the matching by adding optional arguements to edit\n",
    "df['edited_precinct_name'] = df['original_precinct_name'].apply(lambda name: edit_precinct_name(name,prec_dict=df_to_gdf))\n",
    "gdf['edited_precinct_name'] = gdf['original_precinct_name'].apply(lambda name: edit_precinct_name(name,prec_dict=gdf_to_df))\n",
    "\n",
    "######## Manual Corrections ###########\n",
    "# Make precinct specific corrections here like splitting one precinct into two because of new congressional districts\n",
    "gdf.loc[gdf['VTDST']=='000290','edited_precinct_name'] = 'howard township'\n",
    "gdf.loc[gdf['VTDST']=='000300','edited_precinct_name'] = 'howard borough'\n",
    "\n",
    "# make the 'original_precinct_name, edited_precinct_name' for use in the loop below\n",
    "df['original_precinct_name, edited_precinct_name'] = df[['original_precinct_name','edited_precinct_name']].apply(tuple, axis=1)\n",
    "gdf['original_precinct_name, edited_precinct_name'] = gdf[['original_precinct_name','edited_precinct_name']].apply(tuple, axis=1)\n",
    "\n",
    "######## Matching Framework ###########\n",
    "unmatched_precinct_lst_gdf = []\n",
    "unmatched_precinct_lst_df = []\n",
    "\n",
    "precinct_list_df = sorted(list(df[df['county_id'] == county_id]['original_precinct_name, edited_precinct_name'].unique()), key=lambda x: x[1])\n",
    "precinct_list_gdf = sorted(list(gdf[gdf['county_id'] == county_id]['original_precinct_name, edited_precinct_name'].unique()), key=lambda x: x[1])\n",
    "\n",
    "precinct_set_df = {x[1] for x in precinct_list_df if x[1] not in unmatched_precinct_lst_df}\n",
    "precinct_set_gdf = {x[1] for x in precinct_list_gdf if x[1] not in unmatched_precinct_lst_gdf}\n",
    "\n",
    "unmatched_precincts_df = sorted(list(precinct_set_df - precinct_set_gdf))\n",
    "unmatched_precincts_gdf = sorted(list(precinct_set_gdf - precinct_set_df))\n",
    "n_unmatched = len(unmatched_precincts_df) + len(unmatched_precincts_gdf)\n",
    "if n_unmatched > 0:\n",
    "        print(\"county_id: '{}' | {} precincts in {} | {} precincts in {}:\\n\".format(county_id, len(precinct_list_df), dataset_name_df, len(precinct_list_gdf), dataset_name_gdf))\n",
    "        n_precincts_total = len(precinct_list_df) + len(precinct_list_gdf)\n",
    "        print(n_unmatched, \" precincts are unmatched out of \", n_precincts_total)\n",
    "        df_unmatched = df[(df['edited_precinct_name'].isin(unmatched_precincts_df)) & (df.county_id == county_id)]\n",
    "        gdf_unmatched = gdf[(gdf['edited_precinct_name'].isin(unmatched_precincts_gdf)) & (gdf.county_id == county_id)]\n",
    "        if n_unmatched > 100:\n",
    "            print(\"\\nLook for parterns and use change the parameters to edit_precinct_name accordingly.\\n\")\n",
    "            for index, (original_precinct_name_df, edited_precinct_name_df) in enumerate(precinct_list_df):\n",
    "                original_precinct_name_gdf, edited_precinct_name_gdf = precinct_list_gdf[index]\n",
    "                if edited_precinct_name_df in unmatched_precincts_df and edited_precinct_name_gdf in unmatched_precincts_gdf:\n",
    "                    print(\"{} <-- {} ({})\".format(edited_precinct_name_df, original_precinct_name_df, dataset_name_df))\n",
    "                    print(\"{} <-- {} ({})\\n\".format(edited_precinct_name_gdf, original_precinct_name_gdf, dataset_name_gdf))\n",
    "        else:\n",
    "            print(\"unmatched_precincts_df ({}) - len = {}| '{}':\".format(dataset_name_df, len(unmatched_precincts_df), county_id), unmatched_precincts_df)\n",
    "            print(\"\\nunmatched_precincts_gdf ({}) - len = {}| '{}':\".format(dataset_name_gdf, len(unmatched_precincts_gdf), county_id), unmatched_precincts_gdf)\n",
    "            precinct_modification_dictionary_df_to_gdf = {unmatched_precincts_df[i]: unmatched_precincts_gdf[i] if i < len(unmatched_precincts_gdf) else '' for i in range(len(unmatched_precincts_df))}\n",
    "            precinct_modification_dicitonary_gdf_to_df = {unmatched_precincts_gdf[i]: unmatched_precincts_df[i] if i < len(unmatched_precincts_df) else '' for i in range(len(unmatched_precincts_gdf))}\n",
    "            print(\"{}  to {} precinct modification dictionary: \".format(dataset_name_df, dataset_name_gdf))\n",
    "            print(\"'{}':\".format(county_id))\n",
    "            pprint(precinct_modification_dictionary_df_to_gdf)\n",
    "            print(\"{}  to {} precinct modification dictionary: \".format(dataset_name_gdf, dataset_name_df))\n",
    "            print(\"'{}':\".format(county_id))\n",
    "            pprint(precinct_modification_dicitonary_gdf_to_df)\n",
    "            for index, (original_precinct_name_df, edited_precinct_name_df) in enumerate(precinct_list_df):\n",
    "                original_precinct_name_gdf, edited_precinct_name_gdf = precinct_list_gdf[index]\n",
    "                if edited_precinct_name_df in unmatched_precincts_df or edited_precinct_name_gdf in unmatched_precincts_gdf:\n",
    "                    print(\"{} <-- {} ({})\".format(edited_precinct_name_df, original_precinct_name_df, dataset_name_df))\n",
    "                    print(\"{} <-- {} ({})\\n\".format(edited_precinct_name_gdf, original_precinct_name_gdf, dataset_name_gdf))\n",
    "            else:\n",
    "                print(\"Add unmatched precincts to the unmatched precinct.\")\n",
    "else:\n",
    "    print(\"All Done! (make sure you have one to one matches)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
